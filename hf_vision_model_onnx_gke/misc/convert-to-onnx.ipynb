{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba34196-0af7-48d4-9f75-0b5b1ddbbac1",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602ccc26-2ece-4b7f-a2af-70f94518e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers onnxruntime==1.11.0 tf2onnx -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275c7e38-b5a5-42c8-bf5a-c4dca9a6a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f67da7-f6f7-41f1-a310-3cac286fdb9b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406a8740-2ced-4f12-bfa7-0241921b40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, TFViTForImageClassification\n",
    "import numpy as np\n",
    "\n",
    "import onnx\n",
    "import timeit\n",
    "import tf2onnx\n",
    "import tensorflow as tf\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff4433-a643-48fa-b96e-a3282ff7c36e",
   "metadata": {},
   "source": [
    "## Load model and feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98809dcc-8769-401a-b92a-d44445979e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 68.0k/68.0k [00:00<00:00, 2.40MB/s]\n",
      "Downloading tf_model.h5: 100%|██████████| 330M/330M [00:03<00:00, 97.1MB/s] \n",
      "2022-07-30 13:47:50.073866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-30 13:47:50.073906: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-30 13:47:50.073924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2-onnx): /proc/driver/nvidia/version does not exist\n",
      "2022-07-30 13:47:50.074160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFViTForImageClassification.\n",
      "\n",
      "All the layers of TFViTForImageClassification were initialized from the model checkpoint at google/vit-base-patch16-224.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\n",
      "Downloading preprocessor_config.json: 100%|██████████| 160/160 [00:00<00:00, 124kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"google/vit-base-patch16-224\"\n",
    "\n",
    "model = TFViTForImageClassification.from_pretrained(model_ckpt)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6919136-299b-49ff-91f2-232ce46fc8c8",
   "metadata": {},
   "source": [
    "## Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042f1118-c39f-4e95-9fa0-7ed2d5cec0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 13:48:35.619513: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-07-30 13:48:35.619679: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tf2onnx/tf_loader.py:711: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 13:48:44.081644: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-07-30 13:48:44.082179: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n"
     ]
    }
   ],
   "source": [
    "input_size = feature_extractor.size\n",
    "input_signature = [\n",
    "    tf.TensorSpec([None, 3, input_size, input_size], tf.float32, name=\"pixel_values\")\n",
    "]\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=15)\n",
    "onnx_model_path = model_ckpt.split(\"/\")[-1] + \".onnx\"\n",
    "onnx.save(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1012c89-e79b-440c-9068-7aacf5013a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 331M Jul 30 13:49 vit-base-patch16-224.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {onnx_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410959a-e9f7-4eba-8eb8-7fe5a55a49f9",
   "metadata": {},
   "source": [
    "## Benchmarking speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd40a663-8d28-4ee9-a4d3-7ac21eb1c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_inputs = tf.random.normal((1, 3, input_size, input_size))\n",
    "dummy_inputs_numpy = dummy_inputs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b4c79a-b6cd-40bf-a859-b61934ba0b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_outputs = model(dummy_inputs, training=False)\n",
    "\n",
    "sess = ort.InferenceSession(onnx_model_path)\n",
    "ort_outputs = sess.run(None, {\"pixel_values\": dummy_inputs_numpy})\n",
    "\n",
    "np.allclose(tf_outputs.logits.numpy(), ort_outputs, rtol=1e-5, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5106f37-4108-46de-9e03-b0faa4aebbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking TF model...\n",
      "Average latency (seconds): 0.33623785984000276.\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmarking TF model...\")\n",
    "for _ in range(2):\n",
    "    _ = model(dummy_inputs, training=False)\n",
    "\n",
    "# Timing\n",
    "tf_runtimes = timeit.repeat(\n",
    "    lambda: model(dummy_inputs, training=False), number=1, repeat=25\n",
    ")\n",
    "print(f\"Average latency (seconds): {np.mean(tf_runtimes)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea715f20-3877-467c-af5a-89b7621b94d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (seconds): 0.21896604576000755.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    _ = sess.run(None, {\"pixel_values\": dummy_inputs_numpy})\n",
    "\n",
    "# Timing\n",
    "onnx_runtimes = timeit.repeat(\n",
    "    lambda: sess.run(None, {\"pixel_values\": dummy_inputs_numpy}), number=1, repeat=25\n",
    ")\n",
    "print(f\"Average latency (seconds): {np.mean(onnx_runtimes)}.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
